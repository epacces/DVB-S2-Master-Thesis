
\chapter{DVB-S2 MODEM Concepts and Architecture}



\section{Modulation and Coding Schemes}
The coding/modulation (C/M) problem consists of finding practical ways of communicating discrete messages reliably on a realistic channel: this may involve space and satellite communications, data transmission over twisted-pair telephone wires, shielded cable-TV wire, data storage, digital audio/video transmission, mobile communication, terrestrial radio, deep-space radio, indoor radio, or file transfer. The channel causes transmission quality degradation degraded, as it includes attenuation, thermal noise, intersymbol interference, multiple-user interference, multipath propagation, and power limitations.
The most general statement about the selection of a C/M scheme is that it should make the
best possible use of the resources available for transmission, bandwidth, power, and complexity, in order to achieve a required Quality of Service (QoS), i.e, the specified minimum performance requirement imposed on the service. Typically, the latter is expressed in terms of error probability, which is a decreasing function of the signal-to-noise ratio (SNR). Sensible strategies for C/M design must define a trade-off on four factors:

\begin{itemize}
\item The requirement on error probability, which tells us how reliable the transmission is.
\item The available bandwidth (or spectral) efficiency, which measures the efficiency in bandwidth expenditure.
\item The signal-to-noise ratio (SNR) necessary to achieve the required QoS. This gives us a measure on how efficiently the C/M scheme makes use of the available power.
\item Implementation complexity, which is a measure of the cost of the equipment.
\end{itemize}

\subsection{BICM: How to Obtain Top Performance Using a Single Code and Various Modulations}
Forward Error Correcting codes for satellite applications must combine power efficiency and low BER floor with flexibility and simplicity to allow for high-speed implementation. The existence of practical, simple, and powerful such coding designs for binary modulations has been settled with the advent of turbo codes \cite{b:Turbo} and the recent re-discovery of Low-Density Parity-Check (LDPC) codes \cite{b:LDPCGall}.
In parallel, the field of channel coding for non-binary modulations has evolved significantly in the latest years. Starting with Ungerboeck’s work on Trellis-Coded Modulation (TCM) \cite{b:TCM}, the approach had been to consider channel code and modulation as a single entity, to be jointly designed and demodulated/decoded.

Schemes have been published in the literature, where turbo codes are successfully merged with TCM \cite{b:TCMpunct}. Nevertheless, the elegance and simplicity of Ungerboeck’s original approach gets somewhat lost in a series of ad-hoc adaptations; in
addition the turbo-code should be jointly designed with a given modulation, a solution impractical for system supporting several constellations. A new pragmatic paradigm has crystallized under the name of Bit-Interleaved Coded Modulation (BICM) \cite{b:BICM}, where extremely good results are obtained with a standard non-optimized, code. An additional advantage of BICM is its inherent flexibility, as a single mother code can be used for several modulations, an appealing feature for broadband satellite communication systems where a large set of spectral efficiencies is needed.

\subsection{Choice of Modulation Scheme}
Some key issues, such as usage of increasingly high frequency bands (e.g., from X, Ku, up to Ka and Q) and large deployable spacecraft antennas providing high gain, together with availability of high on-board power attainable by large platforms currently subject of studies, have moved the focus from good-old modulation schemes, such as QPSK, to higher order modulation schemes, better providing the high data rate required from up-to-date applications such as internet via satellite, or DVB DNSG (Digital Satellite News Gathering).

Digital transmissions via satellite are affected by power and bandwidth limitations. Satellites, in fact, were originally born power limited and this limitation is still the major constraint in satellite communications. Therefore DVB-S2 provides for many transmission modes (FEC coding and modulations), giving different trade-offs between power and spectrum efficiency.
Code rates of 1/4, 1/3, 2/5, 1/2, 3/5, 2/3, 3/4, 4/5, 5/6, 8/9 and 9/10 are available depending on the selected modulation and the system requirements.
Coding rates 1/4, 1/3 and 2/5 have been introduced to operate, in combination with QPSK, under exceptionally poor link conditions, where the signal level is below the noise level. Computer simulations demonstrated the superiority of such modes over BPSK modulation combined with code rates 1/2, 2/3 and 4/5.
The introduction of two FEC code block length (64800 and 16200) was dictated by two opposite needs: the C/N performance improves for long block lengths, but the end-to-end modem latency increases as well.
Therefore for applications not critical for delays (such as for example broadcasting) the long frames are the best solution, while for interactive applications a shorter frame may be more efficient when a short information packet has to be forwarded immediately by the transmitting station. Four modulation modes can be selected for the transmitted payload
Modulation formats provided by DVB-S2:
\begin{description}
  \item[QPSK and 8-PSK] which are typically employed in broadcast application since they have a constant envelope and therefore can be used for in nonlinear satellite transponders near to saturation operating regime;
  \item[16-APSK and 32-APSK] schemes can also used for broadcasting, but these require an higher level of available \(C/N\) ratio and, furthermore, the adoption of pre-distortion technique.
\end{description}

\begin{figure}
\centering
\input{Constellations.tex}
\caption{QPSK and 8-PSK DVB-S2 constellations with normalized radius \(\rho=1\)} \label{fig:Q8PSK}
\end{figure}

\begin{figure}
\centering
\input{const2.tex}
\caption{APSK constellations with normalized mean energy}
\label{dd}
\end{figure}

%\subsubsection{Draft about BICM}
%Starting with Ungerboeck’s work on Trellis-Coded Modulation
%(TCM) \cite{b:TCM}, the approach had been to consider channel code and modulation as a single entity,
%to be jointly designed and demodulated/decoded. Schemes have been published in the literature,
%where turbo codes are successfully merged with TCM [14]. Nevertheless, the elegance and simplicity
%of Ungerboeck’s original approach gets somewhat lost in a series of ad-hoc adaptations; in addition the turbo-code should be jointly designed with a given modulation, a solution impractical for system supporting several constellations. A new pragmatic paradigm has crystallized under
%the name of Bit-Interleaved Coded Modulation (BICM) \cite{b:BICM}, where extremely good results are
%obtained with a standard non-optimized, code. An additional advantage of BICM is its inherent
%flexibility, as a single mother code can be used for several modulations, an appealing feature for
%broadband satellite communication systems where a large set of spectral efficiencies is needed.
%%A remarkable conclusion is that BICM with Gray mapping preserves the properties of the code regardless
%%of the modulation used, since we observe that the requirements for non-binary modulations

\subsection{The Ultimate Bounds to Compare Modem Performance}

As said by Shannon in 1948, year of publication of his paper \cite{b:Shannon}, ``the fundamental problem of communication is that of reproducing either exactly or approximately a message selected at the another point''. Shannon in his work set up the basis of the Information Theory. As also pointed out by Hartley, he defined as the most natural choice the logarithmic measure of information, putting in relation reliable transmission with statistical characterizations of channels.

From an engineering point of view, one of the most important point raised up by Shannon's work is the relationship between the mean power available at the transmitters and the communications reliability.
One of most important aims in satellite applications is often finding the best trade-offs between the above quantities. This is prevalently due to limited power resources on-board which have to be exploited in the most efficient way. For example, wastes of power would provoke the decreasing not only of the satellite mean lifetime, but also the communication throughput.

By using Shannon theorem upon channel capacity, an important limit on communications performance is achievable. From his theorem in \cite{b:Shannon}, the capacity of a discrete-time additive white Gaussian noise (AWGN) channel is given by
\begin{equation} \label{eq:Capbpt}
C = \frac{1}{2} \log_2( 1 + \frac{S}{N})\unit{bits/transmission}
\end{equation}
When dealing with a continuous-time, bandlimited, additive white Gaussian noise channel with noise power spectral density \(\frac{N\ped{0}}{2}\), input power constraint \(P\), and bandwidth \(W\), one can sample at the Nyquist rate\footnote{Sampling at Nyquist rate simply means to eliminate inter-symbol interference (ISI) while making channel discrete and memoryless. In other words, each symbol to be transmitted over the channel is made independent (obviously at the output) from the others.} and obtain a discrete time channel. The power per sample will be \(P\) and the noise power per sample will be \(WN\ped 0\). Substituting these results in \eqref{eq:Capbpt}, we obtain
\begin{equation}
C = \frac{1}{2}\log_2\left(1+\frac{P}{N\ped{0}W}\right) \unit{bits/transmission}
\end{equation}
If we multiply this result by the number of transmissions per second, which is \(2W\), we obtain the channel capacity in bps
\begin{equation}
C = W \log_2\left(1+\frac{P}{N\ped{0}W}\right) \unit{bps}
\end{equation}
From this result, the basic factors that determine the channel capacity are the channel bandwidth \(W\), the noise power spectrum \(N\ped{0}\), and the signal power \(P\). There exists a tradeoff between \(P\) and \(W\) in the sense that one can compensate for the other.

Increasing the input signal power obviously increases the channel capacity, because when one has more power to spend, one can choose a larger number of input levels that are far apart, and therefore more information bits per transmission are possible. However, the increase in capacity as a function of power is logarithmic and slow. This is because if one is transmitting with a certain level of immunity against noise and wants to increase the number of input levels, one has to introduce new levels with amplitudes higher than the existing levels, and this requires a lot of power. This fact notwithstanding, the capacity of the channel can be increased to any value by increasing the input power.

The effect of the channel bandwidth, however, is quite different. Increasing \(W\) has two contrasting effects. On one hand, on a higher bandwidth channel one can transmit more samples per second and therefore increase the transmission rate. On the other hand, a higher bandwidth means higher input noise to the receiver and this degrades its performance. Letting the bandwidth \(W\) tend to infinity, one can observe that, contrary to the power case, capacity can not be increased to any desired value by increasing the bandwidth alone.

In any practical communication system we must have \(R < C\). If an AWGN channel is employed, we have
\begin{equation}
R < W \log_2 \left( 1+\frac{P}{N\ped{0}W}\right)
\end{equation}
By dividing both sides by \(W\) and defining \(\eta=\frac{R}{W}\), the spectral efficiency measured in \(\frac{\unit{bit}}{\unit{Hz}}\), we obtain
\begin{equation}
\eta < \log_2\left(1+\frac{P}{N\ped{0}W} \right)
\end{equation}
If \(E\ped{b}\) is the energy per bit, then \(E\ped b=\frac{P}{R}\). By substituting in the previous relation, we obtain\footnote{If we define \(W\) as the the equivalent noise bandwidth on the Nyquist shaping filter, which is typically chosen in communications to eliminate ISI contribution, we obtain independently from any roll-off factor that \(W=R\ped{b}\). Note that, in fact, for the specific symmetry of Nyquist pulse the equivalent noise bandwidth on this pulse does not change with roll-off factor variation. Hence the reason of simplification \(\frac{E\ped{b}R\ped{b}}{N\ped 0 W}=\frac{E\ped{b}}{N\ped 0}\) made in this relation. }
\begin{equation}
\eta < \log_2\left(1+\eta\frac{E\ped b}{N\ped{0}} \right)
\end{equation}
This relation is plotted in \figref{f:ShBou}. The curve defined by
\begin{equation}
\frac{E\ped b}{N \ped 0} = \log_{10}\left(\frac{2^{\eta}-1}{\eta} \right)
\end{equation}
divides the plane in two regions. In one region (above the curve) reliable communication is possible, and in the other region (below the curve) reliable communication is not possible. The performance of any communication system can be denoted by a point in this plane and the closer the point is to this curve, the closer is the performance of the system to an optimal system. From this curve it is seen that
\begin{equation}
\frac{E\ped b}{N\ped 0}=\ln 2= 0,693\sim -1,592 \unit{dB}
\end{equation}
is an absolute minimum for reliable communication. In other words, for reliable communications, we must have
\begin{equation}
\frac{E\ped b}{N\ped 0}>0,693
\end{equation}
In \figref{f:ShBou}, when \(\eta \ll 1 \), we are dealing with a case where bandwidth is large and the main concern is limitation on power. This case is usually referred to as the \emph{power limited case}. Signaling schemes with high dimensionality, such as orthogonal, biorthogonal, and simplex, are frequently used in these cases. The case, where \(\eta \gg 1\) happens when the bandwidth of the channel is small, and therefore is referred to as the \emph{bandwidth limited case}. Low-dimensional signaling schemes with crowded constellations are implemented in this case.

%\footnote{\(W\) is in general the equivalent noise bandwidth. Only in case of an ideal shape filter (i.e., with a roll-off \(\alpha=0\)), the noise power per sample is\[P\ped{N}= \int_{-W}{+W} \] }

%Hence, to transmit reliably any message, not more that \(C\) information bits per each symbol interval can be transmitted. Therefore transmission rate is limited by
%\begin{equation}
%R\ped{b} < \frac{1}{2T} \log_2 \left(1+ \frac{S}{N} \right)
%\end{equation}
%where the second member of equation represent the capacity measured in bps. In optimal transmission condition, for the sampling theorem, the bandwidth allowing to transmit independent samples for each \(T\) seconds is \(W = 1/(2T) \)\footnote{For a base-band signal and an ideal roll-off factor of the shaping filter}.
%
%In other words, given an average power constraint at the transmitter and a bandwidth limitation on the channel, Shannon in his work proved that the channel capacity over additive white gaussian channel (AWGN)
%\begin{equation}
%C= W \log_2 \left( 1+ \frac{E\ped{b} R\ped{b}}{W N_0}  \right)
%\end{equation}
%is a upper limit on the transmission rate over AWGN channel.
%This means that any point above the heavy line in \figref{f:ShBou} can be attained and those below cannot. Now, putting in evidence \(C/W\) ratio, called spectral efficiency, we have therefore
%\begin{equation}
%\frac{E_b}{N_0} > 10 \log_{10} \left( \frac{2^{\eta}-1}{\eta}  \right)
%\end{equation}
%in terms of signal to noise ratio (SNR). In other words, Shannon Bound represent the lowest power limit necessary but non sufficient to reach any spectral efficiency together with reliable transmissions.
%
%Plot of the Shannon Bound in terms of spectral efficiency versus Signal-to-Noise Ratio (SNR) put in evidence two interesting areas: power and bandwidth limited. Figure \ref{f:ShBou} puts in evidence two region which have a considerable importance in digital communication.

%\begin{itemize}
%\item The left part ($\frac{R\ped b}{W} < 1$) of \figref{f:ShBou} correspond to transmissions with a greater amount of bandwidth compared to the power available at the transmitter. Hence this region is called power limited. .
%
%\item The right region ($\frac{R\ped b}{W} > 1$) represent a transmission system having strictly limitation on the usable bandwidth without an analogous constraint on the power to be transmitted.
%\end{itemize}

Plotting on the spectral efficiency--average power plane performance of several modulation schemes, we could observe that the SNR penalty (referred to Shannon limit) decreases with increasing of the modulation order $M$. In other words, at the expense of an higher complexity, performance very close to Shannon limit can be achieved. However, in this manner, the system would operate at spectral efficiencies excessively small or big if compared to those commonly required.

\begin{figure} \centering
\input{bound.tex}
\caption{Shannon Bound: On the horizontal axis is reported spectral efficiency \(\eta\), on the vertical axis Signal-to-Noise Ratio measured in \(\unit{dB}\); Dotted line at \(-1.6 \unit{dB}\) represents the asymptotic value for \(\eta \simeq 0\); Heavy line is the Shannon curve above which every point must stays }\label{f:ShBou}
\end{figure}

As we shall see in details in \secref{sec:Perf}, \figref{f:Perf} shows performance for each modulation and coding (C/M) scheme adopted by DVB-S2 modulator with respect to the calculated Shannon limit. Thanks to an optimized choice on C/M schemes, the DVB-S2 modulator provides a wide range of spectral efficiencies  (see \tbref{tb:EtaPerf}) while ensuring performance very close to the Shannon limit.



\subsection{Adaptive Coding Modulation}

Adaptive Coding Modulation (ACM) technique allows different modulation formats and error protection levels (i.e. coding rates) to be used and changed on a frame-by-frame
basis within the transmitted data stream. By means of a return channel, informing the transmitter of the actual receiving condition, the transmission parameters may be optimized for each individual user, dependant on link conditions. Today ACM is considered as a powerful tool to further increase system capacity, allowing for better utilization of transponder resources.

Since it well-known that the higher the frequency bands used, the less the link performance tends to remain location-independent and stationary (i.e. stable space wise), countermeasures to counteract the above link variations are required. One can adopt static or dynamic solution: adopting static countermeasures against propagation effects simply means to dimension link parameters (e.g. antenna diameter, power) on worst case basis (link budgets usually contain an item called `propagation margin at nn \% of time'); on the other hand, the most common form of dynamic countermeasure is power control, a technique to manage both propagation phenomena.
Despite the beneficial power control effect on system efficiency, when for instance a user up-link operates in clear weather or in light of traffic conditions, the potentiality of that link is not fully exploited. In other words power control helps, but does not solve to the problem of system parameters over-sizing.

Current point-to-point multi-beam satellite systems based on the DVB-S standard are designed for link closure in the worst-case propagation and location conditions. The old DVB-S standard, envisaged for broadcasting applications, considers a
fixed coding rate and modulation format, which are selected according to the assumed coverage and availability requirements. This approach implies the necessity of high margins in the majority of the cases, when interference and propagation conditions allow for higher Signal to Interference plus Noise Ratio (SNIR). Typical Ku-band broadcasting
links are designed with a clear-sky margin of 4 dB to 6 dB and a service availability target of about 99\% of the worst month (or 99,6\% of the average year). Since the rain attenuation curves are very steep in the region 99\% to 99,9\% of
the time, many dBs of the transmitted satellite power are useful, in a given receiving location, for only some ten minutes per year. Unfortunately, this waste of satellite power/capacity cannot be easily avoided for broadcasting services, where
millions of users, spread over very large geographical areas, receive the same content at the same time.

However, this design methodology, devised for broadcasting systems, is not optimal for unicast networks. In fact, the point-to-point nature of link connections allows exploiting spatial and temporal variability of end-user channel
conditions for increasing average system throughput. This is achieved by adapting coding rate and modulation format
(ACM) to best match the user SNIR, thus making the received data rate location and time dependent. Fixed link margins are therefore avoided and a remarkable improvement in system capacity is obtained thanks to better utilization
of system power resources.

Assuming a fixed beam power allocation, the key parameters responsible for SNIR variability within the satellite coverage are the fading attenuation, the satellite antenna gain and the antenna \(C/I\). The fading attenuation variation is
due to both geographical dependency of rain statistics and to propagation channel time variations.

One of the key factors, which can heavily affect capacity, is the granularity of physical layer schemes supported by the
system. It is important to ensure a reasonably small step in \(E\ped s/N\ped 0\) and spectral efficiency between consecutive schemes
in order to maximize the data rate provided to STs. In particular, it is of the highest importance for capacity purposes
utilizing a sufficiently fine granularity in the SNIR range experienced in the coverage during clear sky conditions. On the contrary, larger SNIR intervals can be assumed between the more robust modes without major capacity penalty, due to their lower occurrence probability.

The DVB-S2 ACM modulator operates at constant symbol rate, since the available transponder bandwidth is assumed constant. ACM is implemented by the DVB-S2 modulator by transmitting a TDM sequence of physical layer frames, each transporting a coded block and adopting a uniform modulation format. However, when ACM is implemented, coding scheme and modulation format may change frame-by-frame. Therefore service continuity is achieved, during rain fades, by reducing user bits while increasing at the same time FEC redundancy and/or modulation ruggedness.

ACM technique therefore allows to significantly increase the average system throughput and availability of satellite networks, thus making the system economically more attractive for interactive applications. The increase is mainly dependant on the adopted frequency band, target link and service area availability requirements and related system sizing options. Compared to Constant Coding and Modulation (CCM), an ACM-based system can provide:

\begin{itemize}
\item higher system throughput than the one supported by a CCM system, as an ACM system can take benefit from better link propagation and beam C/I conditions than the worst case link on which CCM physical layer is sized;
\item higher availability (time-link and/or spatial) than the one supported by the CCM system as when deeper fading occurs the ACM system can use a more robust modulation and coding scheme. This is obtained through a very small reduction of the total system throughput as the number of users affected by these deep fade events is very limited. The highest link availability and service area supported by the system depends on the lowest modulation and coding scheme supported by the system;
\item more optimization dimensions in the system design to cope with more pushed frequency reuse and more complex satellite antennas.
\end{itemize}

%\section{Bit Scrambling and Interleaving}
\section{ACM Modem System Description}

DVB-S2 ACM Modem system is defined as the functional block of equipment performing the adaptation of the baseband digital signals, from the output of a single (or multiple) MPEG transport stream multiplexer(s), or from the output of a single (or multiple) generic data source(s), to the satellite channel characteristics. Data services may be transported in Transport Stream format (e.g. using Multi-protocol Encapsulation\footnote{It is a means to allow more than a packet format (e.g., IP) over MPEG frames.}) or Generic Stream format.

If the received signal is above the \(C/N+I\) threshold, the Forward Error Correction (FEC) technique adopted in the System is designed to provide a `Quasi Error Free' (QEF) quality target. The definition of QEF adopted for DVB-S2 is ``less than one uncorrected error-event per transmission hour at the level of a 5 Mbit/s single TV service decoder'', approximately corresponding to a Transport Stream Packet Error Ratio \(\mathrm{PER}< 10^{-7}\) before de-multiplexer.

\subsection{Architecture and Sub-Blocks Specifications}

According to \figref{fig:DVBSys}, the DVB-S2 System is composed of a sequence of functional blocks as described below.

\begin{description}
\item[Mode Adaptation] is application dependent. It provides input stream interfacing, Input Stream Synchronization (optional), null-packet deletion (for ACM and Transport Stream input format only), CRC-8 coding for error detection at packet level in the receiver (for packetized input streams only), merging of input streams (for Multiple Input Stream modes only) and slicing into DATA FIELDs. For Constant Coding and Modulation (CCM) and single input Transport Stream, Mode Adaptation consists of a "transparent" DVB-ASI (or DVB-parallel) to logical-bit conversion and CRC-8 coding. %For Adaptive Coding and Modulation (ACM), Mode Adaptation shall be according to annex D.

    A Base-Band Header is appended in front of the Data Field, to notify the receiver of the input stream format and Mode Adaptation type. To be noted that the MPEG multiplex transport packets may be asynchronously mapped to the Base-Band Frames.
\item[Stream Adaptation] is applied to provide padding to complete a Base-Band Frame and Base-Band Scrambling.
\item[Forward Error Correction (FEC) Encoding] is carried out by the concatenation of BCH outer codes and LDPC (Low Density Parity Check) inner codes (rates 1/4, 1/3, 2/5, 1/2, 3/5, 2/3, 3/4, 4/5, 5/6, 8/9, 9/10). Depending on the application area, the FEC coded blocks have length \(n\ped{ldpc}= 64 800\) bits or 16 200 bits. When VCM and ACM is used, FEC and modulation mode may be changed in different frames, but remains constant within a frame. %For Backwards Compatible modes, the bit-stream at the output of the FEC encoder should be processed according to annex F.
    Bit interleaving is applied to FEC coded bits for 8PSK, 16APSK and 32APSK.
\item[Mapping] into QPSK, 8PSK, 16APSK and 32APSK constellations is applied, depending on the application area. Gray mapping of constellations is used for QPSK and 8PSK.
\item[Physical Layer Framing] Physical layer framing should be applied, synchronous with the FEC frames, to provide Dummy PLFRAME insertion, Physical Layer (PL) Signalling, pilot symbols insertion (optional) and Physical Layer Scrambling for energy dispersal. Dummy PLFRAMEs are transmitted when no useful data is ready to be sent on the channel. The System provides a regular physical layer framing structure, based on SLOTs of \(M = 90\) modulated symbols, allowing reliable receiver synchronization on the FEC block structure. A slot is devoted to physical layer signalling, including Start-of-Frame delimitation and transmission mode definition. This mechanism is suitable also for VCM and ACM demodulator setting. Carrier recovery in the receivers may be facilitated by the introduction of a regular raster of pilot symbols (\(P = 36\) pilot symbols every 16 SLOTs of 90 symbols), while a pilot-less transmission mode is also available, offering an additional 2,4\% useful capacity.
\item[Base-Band Filtering and Quadrature Modulation] is applied to shape the signal spectrum (squared-root raised cosine, roll-off factors 0,35 or 0,25 or 0,20) and to generate the RF signal.
\end{description}

\begin{figure} \centering
\includegraphics[scale=0.6]{DVBS2}
\caption{Functional block diagram of DVB-S2 ACM modem architecture} \label{fig:DVBSys}
\end{figure}


\subsection{Sub-Blocks Description}

The following subsystems description is organized according to the functional block diagram in \figref{fig:DVBSys}.

\subsubsection{Mode Adaptation}

DVB-S2 modem architecture deals with various input sequences:
\begin{itemize}
\item Single or multiple Transport Streams (TS), which are characterized by User Packets (UPs) of constant length equal to \(\unit{UPL} = 188\unit{bytes}\) (one MPEG packet) whose first byte is a sync-byte (\(47\ped{HEX}\));
\item Single or multiple Generic Streams (GS), which are characterized by continuous bit streams or streams of constant length user packets.
\end{itemize}
The first input bit is interpreted as the most significant bit (MSB). ACM command signaling allows setting of the transmission parameters to be adopted by DVB-S2 modulator, for a specific portion of input data.

Since the DVB-S2 modulator may produce variable transmission delay on the user information, the Input Stream Synchronizer provides a means to guarantee a constant bit rate (CBR) and constant end-to-end transmission delay.

The identification and erasure of MPEG null-packets allow to reduce the information rate and increase the error protection in the modulator. This process is carried out in a way that the removed null-packets can be re-inserted in the receiver in the exact place where they originally were. Specifications on this process are available in dedicated annex in \cite{b:DVBstandard}.

A systematic Cyclic Redundancy Check (CRC) encoding is provided so that the receiver can detect the presence of errors in received streams. The CRC of 8 bits is inserted in the Base-Band Header (BBHEADER), which has the overall length of 80 bits. BBHEADERs contain also other signaling information such as indications on the roll-off factor of the shaping filter (Square Root Raised Cosine), the presence/absence of padding bits, Adaptive/Constant Coding Modulation, the use of identification and erasure of null-packet function, etc.

\subsubsection{Stream Adaptation}
Stream adaptation (see \figref{fig:strformat}) provides padding to complete a constant length (\(k\ped{bch}\) bits) BBFRAME and scrambling. \(k\ped{bch}\) depends on the FEC rate, as reported in \tbref{tb:codpar}. Padding may be applied in circumstances when the user data available for transmission are not sufficient to completely fill a BBFRAME, or when an integer number of UPs has to be allocated in a BBFRAME.
The input stream consists of a BBHEADER followed by a DATA FIELD. The output stream will be a BBFRAME.
\begin{figure} \centering
\includegraphics{data}
\caption{BBFRAME format at the output of the STREAM ADAPTER}\label{fig:strformat}
\end{figure}
\begin{description}
\item[PADDING] \(k\ped{bch} - \mathrm{DFL}-80\) zero bits are appended after the DATA FIELD so that the resulting BBFRAME have the a constant length of \(k\ped{bch}\) bits. For Broadcast Service applications, \(\mathrm{DFL}= k\ped{bch}-80\), therefore no padding must be applied.
\item[SCRAMBLING] The complete BBFRAME should be randomized and the randomization sequence should be synchronous with the BBFRAME, starting from the MSB and ending after \(k\ped{bch}\) bits. Scrambling sequences are typically generated by feed-back shift registers. There are two main reasons why scrambling is used:
    \begin{itemize}
    \item It facilitates the work of a timing recovery circuit, an automatic gain control and other adaptive circuits of the receiver (eliminating long sequences consisting of 0 or 1 only).
    \item  It eliminates the dependence of a signal's power spectrum upon the actual transmitted data, making it more dispersed to meet maximum power spectral density requirements (because if the power is concentrated in a narrow frequency band, it can interfere\footnote{Standardization committees such as ETSI (European Telecommunications Standard Institute) have imposed various rules as to interferences.} with adjacent channels due to the cross modulation and the intermodulation caused by non-linearities of the receiving tract).
    \end{itemize}
\end{description}

\subsubsection{FEC Encoding}

This subsystem performs Outer Coding (BCH), Inner Coding (LDPC) and Bit Interleaving. The input stream is composed of BBFRAMEs and the output stream of FECFRAMEs.

Each BBFRAME (\(k\ped{bch}\) bits) is processed from the MSB to LSB by the FEC coding subsystem to generate a FECFRAME (\(n\ped{ldpc}\) bits). The parity check bits (BCHFEC) of the systematic BCH outer code must be appended after the BBFRAME and the parity check bits (LDPCFEC) of the inner LDPC encoder must be appended after the BCHFEC field, as shown in \figref{fig:fecformat}.

%We shall give more details as to FEC Encoding and Interleaving in the next sections.
\begin{figure} \centering
\includegraphics{FECformat}
\caption{Format of data before Bit Interleaving} \label{fig:fecformat}
\end{figure}

For 8PSK, 16APSK, and 32APSK modulation formats, the output of the LDPC encoder is bit interleaved using a block interleaver (see \figref{fig:BI} and \figref{fig:BI35}). Data is serially written into the interleaver column-wise, and serially read out row-wise (the MSB of BBHEADER is read out first, except 8PSK rate 3/5 case where MSB of BBHEADER is read out third) as shown in the figures.


\begin{figure} \centering
\includegraphics{Inter1}
\caption{Bit Interleaving scheme for 8PSK (for each rate except from 3/5) and normal FECFRAME length} \label{fig:BI}
\end{figure}


\begin{figure} \centering
\includegraphics{Inter2}
\caption{Bit Interleaving scheme for 8PSK (rate 3/5) and normal FECFRAME length} \label{fig:BI35}
\end{figure}

\begin{table}
\begin{center}\begin{tabular}{|c|c|c|c|}
\hline
 Modulation &  Rows (\(n=64800\)) &  Rows (\(n=16200\)) & Columns \\
\hline
 8PSK &  21600 &  5400 & 3 \\
 16APSK &  16200 &  4050 & 4 \\
 32APSK &  12960 &  3240 & 5 \\
\hline
\end{tabular}\end{center}
\caption{Bit Interleaver structure}
\end{table}
%\section{Outer FEC: The BCH Code} \label{sec:BCHdes}

\subsubsection{Bit Mapping}

Each FECFRAME (which is a sequence of 64 800 bits for normal FECFRAME, or 16 200 bits for short FECFRAME), must be serial-to-parallel converted (parallelism level \(\eta\ped{MOD}\)= 2 for QPSK, 3 for 8PSK, 4 for 16APSK, 5 for 32APSK) in figures 9 to 12, the MSB of the FECFRAME is mapped into the MSB of the first parallel sequence.
Each parallel sequence shall be mapped into constellation, generating a \((I,Q)\) sequence of variable length depending on the selected modulation efficiency \(\eta\ped{MOD}\).

The input sequence is a FECFRAME, the output sequence is a XFECFRAME (compleX FECFRAME),
composed of \(64 800/\eta\ped{MOD}\) (normal XFECFRAME) or \(16 200/\eta\ped{MOD}\)(short XFECFRAME) modulation symbols. Each modulation symbol is a complex vector in the format (I,Q) (I being the in-phase component and Q the quadrature
component) or in the equivalent format \( \rho \exp(\mathrm{j}\phi) \)(\(\rho\) being the modulus of the vector and \(\phi\) being its phase).


For QPSK, the System employs conventional Gray-coded QPSK modulation with absolute mapping (no differential coding). Bit mapping into the QPSK constellation is illustrated in \figref{fig:Q8PSK}. The normalized average energy per symbol is equal to \( \rho^2 = 1\).
Two FECFRAME bits are mapped to a QPSK symbol, i.e. bits \(2i\) and \(2i+1\) determines the \(i\)-th QPSK symbol, where \(i = 0 \virgola 1 \virgola 2 \virgola \ldots \virgola (N/2)-1\) and \(N \) is the coded LDPC block size.

For 8PSK, the System employs conventional Gray-coded 8PSK modulation with absolute mapping (no differential coding). Bit mapping into the 8PSK constellation is shown in \figref{fig:Q8PSK}. The normalized average energy per symbol is equal to \(\rho^2 = 1\).
For all the rates excluding \(3/5\), bits \(3i \virgola 3i+1 \virgola 3i+2 \) of the interleaver output determine the \(i\ap{th}\) 8PSK symbol where \(i = 0 \virgola 1 \virgola 2 \virgola \ldots \virgola (N/3)-1 \)and \(N\) is the coded LDPC block size. For rate 3/5 bits \(3i+2 \virgola 3i+1 \virgola 3i \) of the interleaver output determine the \(i\)-th 8PSK symbol where \(I = 0 \virgola 1 \virgola 2 \virgola \ldots \virgola (N/3)-1\) and \(N\) is the coded LDPC block size.

The 16APSK modulation constellation (see figure \figref{fig:Q8PSK}) is composed of two concentric rings of uniformly spaced 4 and 12 PSK points, respectively in the inner ring of radius \(\rho_1\) and outer ring of radius \(\rho_2\).
The ratio of the outer circle radius to the inner circle radius (\(\gamma =\rho_2/\rho_1\)) should be comply with \tbref{tb:16APSK_Radius}.
If \(4{\rho_1}^2+ 12{\rho_2}^2 = 16\) the average signal energy becomes 1.
Bits \(4i, 4i+1, 4i+2\) and \(4i+3\) of the interleaver output determine the \(i\)-th 16APSK symbol, where \(i = 0\virgola 1\virgola 2\virgola \ldots \virgola (N/4)-1\)
and \(N\) is the coded LDPC block size.

The 32APSK modulation constellation (see \figref{fig:Q8PSK}) is composed of three concentric rings of uniformly spaced 4, 12 and 16 PSK points, respectively in the inner ring of radius \(\rho_1\), the intermediate ring of radius \(\rho_2\) and the outer ring
or radius \(\rho_3\). \tbref{tb:32APSK_Radius} defines the values of \(\gamma_1 = \rho_2/\rho_1\) and \(\gamma_2 = \rho_3/ \rho_1\).
If \(4{\rho_1}^2+ 12{\rho_2}^2+ 16{\rho_3}^2 = 32\) the average signal energy becomes equal to 1.
Bits \(5i \virgola 5i+1 \virgola 5i+2 \virgola 5i+3\) and \(5i+4\) of the interleaver output determine the \(i\)-th 32APSK symbol, where \(i = 0 \virgola 1 \virgola 2 \virgola (N/5)-1\).

\begin{table}
\begin{center}\begin{tabular}{|c|p{1.47cm}||p{1.41cm}||p{1.56cm}||}
\hline
 Code Rate &  \multicolumn{1}{p{1.47cm}|}{\centering \(\eta\)} &  \multicolumn{1}{p{1.41cm}|}{\centering \(\gamma_1\)} &  \multicolumn{1}{p{1.56cm}|}{\centering \(\gamma_2\)} \\
\hline
 3/4 &  \multicolumn{1}{p{1.47cm}|}{\centering 3,74} &  \multicolumn{1}{p{1.41cm}|}{\centering 2,84} &  \multicolumn{1}{p{1.56cm}|}{\centering 5,27} \\
 4/5 &  \multicolumn{1}{p{1.47cm}|}{\centering 3,99} &  \multicolumn{1}{p{1.41cm}|}{\centering 2,72} &  \multicolumn{1}{p{1.56cm}|}{\centering 4,87} \\
 5/6 &  \multicolumn{1}{p{1.47cm}|}{\centering 4,15} &  \multicolumn{1}{p{1.41cm}|}{\centering 2,64} &  \multicolumn{1}{p{1.56cm}|}{\centering 4,64} \\
 8/9 &  \multicolumn{1}{p{1.47cm}|}{\centering 4,43} &  \multicolumn{1}{p{1.41cm}|}{\centering 2,54} &  \multicolumn{1}{p{1.56cm}|}{\centering 4,33} \\
 9/10 &  \multicolumn{1}{p{1.47cm}|}{\centering 4,49} &  \multicolumn{1}{p{1.41cm}|}{\centering 2,53} &  \multicolumn{1}{p{1.56cm}|}{\centering 4,3} \\
\hline
\end{tabular}\end{center}
\caption{Optimum constellation radius ratios \(\gamma_1\) and \(\gamma_2\) (linear channel) for 32APSK}
\label{tb:32APSK_Radius}
\end{table}
\begin{table}
\begin{center}\begin{tabular}{|c|c|c|}
\hline
 Code Rate &  \(\eta\) & \(\gamma\) \\
\hline
 2/3 &  2,66 & 3,15 \\
 3/4 &  2,99 & 2,85 \\
 4/5 &  3,19 & 2,75 \\
 5/6 &  3,32 & 2,7 \\
 8/9 &  3,55 & 2,6 \\
 9/10 &  3,59 & 2,57 \\
\hline
\end{tabular}\end{center}
\caption{Optimum constellation radius ratio \(\gamma\) (linear channel) for 16APSK} \label{tb:16APSK_Radius}
\end{table}

\subsubsection{Physical Layer (PL) Framing}
This block generates, synchronously with FECFRAMEs, physical layer frames (PLFRAMEs) and deal with
\begin{itemize}
\item the insertion of physical headers and optional pilot symbols (their insertion causes a loss of 2,4\% of capacity);
\item the insertion of dummy frames to be used in absence of data ready to be immediately transmitted;
\item the scrambling (or the randomization) for energy dispersal by multiplying the \((I+\im Q)\) samples by a complex radomization sequence \(C\ped{I}+ \im C\ped{Q})\).
\end{itemize}

\section{Inner and Outer FEC}

The DVB-S2 FEC section relies on two block codes concatenation, i.e., codewords generated by BHC encoder are, in turn, encoded by LDPC encoder\footnote{Note that each frame (either short or long) is processed from most significant to least significant bit, either by BCH or LDPC.}. Thus, BCH code is usually called \emph{outer code} and LDPC \emph{inner code}. Outputs from FEC encoding section are formatted according to \figref{fig:fecformat}. As we shall see later on, this BCH concatenation gives an extra protection \cite{b:DVBstandard} against unwanted error floors at high SNR\footnote{The \emph{iterative decoding} achieves very close to Shannon limit performance at low/medium  SNR. On the contrary, its performance may be significantly worse at high SNR. In fact, their free distance (the minimum Hamming distance between different codewords, i.e., the minimum Hamming weight of a nonzero codeword) can be low. This causes BER curve to flatten following the error floor tied to \(d\ped{free}\), after the waterfall region at low SNR. Performance of any binary code at high SNR can be well approximated by the expression of union bound, truncated to the contribution of free distance (terms at higher distance are negligible at high SNR). Such expression \cite{b:ErrFloor} is
\[
\mathrm{BER} \simeq \frac{1}{2}\frac{w\ped{free}}{k} \mathrm{erfc} \left( \sqrt{d\ped{free} \frac{k}{n}\frac{E\ped b}{N\ped 0} }\right)
\]}
When the decoding has to be performed, the above sequence of encoding steps must be, of course, inverted: in other words, LDPC starts to decode prior to BCH. As just said, error floor phenomena at high signal-to-noise ratio ineluctably affect the decoding performance, and therefore the BCH extra protection against residual errors is aimed at counteracting to the performance degradation, enhancing FEC robustness at higher SNR.

In a some sense, the chain constituted, in order, by LDPC encoder, channel and LDPC decoder can be conceived as a super-channel on which BCH encoder/decoder operates. This kind of intuitive representation puts in evidence the advantage of concatenating two codes. The best choices on their kind of concatenation can give a powerful tool to enhance the performance of the overall FEC decoding, allowing to act by a outer coding on the weaknesses of the inner coding.


%\subsection{BCH design}
\subsection{BCH}
BCH code is named for Bose, Ray-Chaudhury, and Hocquenghem, who published work in 1959 and1960 which revealed a means of designing codes over $GF(2)$ with a specified design distance. BCH codes are cyclic codes and thus, as explained in Appendix~B, can be specified by a generator polynomial.
In present Section we give only some notations over the particular, as we shall see, structure of BCH code employed in DVB-S2 and, more generally, over its design steps.

A BCH code of length $n$ with a specified minimum distance, or, i.e., capable of correcting (at least) $t$ errors, can be designed as follows \cite{b:moon,b:mcwilliams}:
\begin{enumerate}
\item Determine the smallest $m$ such that $GF(q^m)$ has primitive $n$th root (\secref{sec:factoring}) of unity $\beta$.
\item Select a nonnegative integer $b$. In most of cases, it is selected $b=1$.
\item Write down a list of $2t$ consecutive powers of $\beta$ (see \secref{sec:MathSurvey}):
\[
\beta^b \virgola \beta^{b+1} \virgola \ldots \virgola \beta^{b+2t-1}
\]
Determine the minimal polynomial of each of these powers of $\beta$. (Because of conjugacy, frequently these minimal polynomials are not distinct.)
\item The generator polynomial $g(x)$ is least common multiple (LCM) of these minimal polynomials. The code is a $(n\virgola n-\mathrm{deg}(g(x)))$ cyclic code.
\end{enumerate}

Two fields are involved in the construction of the BCH codes. The small field $GF(q)$ is where the generator polynomial has its coefficients and is the field where the elements of the codeword are. The big field $GF(q^m)$ is the field where the generator polynomial has its roots. For encoding purposes it is only sufficient to have the polynomial generator of the code, whereas, for decoding, the additionally knowledge of the extension field where the generator has its roots is necessary. Two definitions will be useful later on: first, if \(\beta\) selected is a primitive element then the code is called \emph{primitive}; second, when \(\beta=1\) the code is said to be a code in \emph{narrow-sense}.

It can be proved that following the constructive procedure described above produces codes with at least the specified minimum distance. As shown in Appendix B, since every codeword is a multiple of the generator polynomial, we can express the \emph{parity check condition} as follows
\begin{equation}
c(\beta^i)=m(\beta^i)g(\beta^i)=m(\beta^i)\cdot 0
\end{equation}
for \(i=b \virgola b+1 \virgola \ldots \virgola b+2t-1 \). In fact these powers of \(\beta\) are, by design, the roots of \(g(x)\). Rewriting these condition using the correspondent vector representation we get the following system of equations
\begin{equation}
c_0+c_1\beta^i+c_2\beta^{i+1}+\ldots+c_{n-1}{(\beta^{i})}^{n-1}=0
\end{equation}
always for \(i=b \virgola b+1 \virgola \ldots \virgola b+2t-1 \). Therefore \(2t\) parity check conditions can be also expressed in the matrix form
\begin{equation} \label{eq:pchk}
\left(
\begin{array}{ccccc}
  1 & \beta^i & \beta^{2i} & \cdots & \beta^{(n-1)i}
\end{array} \right)
\left(
\begin{array}{c}
  c_0 \\
  c_1 \\
  c_2 \\
  \vdots \\
  c_{n-1}
\end{array}
\right)
=0
\end{equation}
Stacking the row vectors for different values of \(i\) we get the following parity check matrix
\begin{equation}
\left(
  \begin{array}{ccccc}
    1 & \beta^b & \beta^{2b} & \ldots & \beta^{(n-1)b} \\
    1 & \beta^{b+1} & \beta^{2(b+1)} & \ldots & \beta^{(n-1)(b+1)} \\
    \vdots &  &  &  &  \\
    1 & \beta^{b+\delta-3} & \beta^{2(b+\delta-3)} & \ldots & \beta^{(n-1)(b+\delta-3)} \\
    1 & \beta^{b+\delta-2} & \beta^{2(b+\delta-2)} & \ldots & \beta^{(n-1)(b+\delta-2)} \\
  \end{array}
\right)
\end{equation}
where \(\delta=2t+1\) represent the \emph{design distance} (Hamming metric) of the code.

It can be proved (see \cite{b:moon}) that the matrix \(\vet H\) have at least \(\delta = 2t+1\) columns linearly dependent and, thus, the minimum distance of the code satisfies \( d\ped{min} \geq \delta \); that is, the code is capable of correcting at least \(t\) errors.

%\subsection{The Code Structure} \label{sec:BCHstruct}

In DVB-S2 context, BCH outer code has been designed to avoid unpredictable and unwanted error floors which affect iterative decodings at high \(C/N\) ratios, i.e., at low bit error rates (BER).

Although the mathematical background shown in this thesis in order to design, encoding and decoding is completely general, in the most practical cases the base fields of BCH codes is \(GF(2)\), as in DVB-S2 error protection section.  The polynomials which must be multiplied in order to obtain the wanted BCH code associated to a specific operating mode (or, i.e., error correction capability) are shown in Table \ref{tb:BCHpoly}. More specifically, multiplication of the first \(t\) of them provides a polynomial generator of the BCH code capable of correcting at least \(t\) error.   Notice that this procedure is in accordance with the third step to construct generator polynomial of the BCH code.

The encoding suggestions, provided in \cite{b:DVBstandard}, are typical of a cyclic codes in systematic form, whose specific properties and encoding steps are discussed in dedicated Appendix B. It is worth understanding that both systematic and non-systematic codewords are always multiple of the generator polynomial of the code (or, i.e., of the ideal, as also shown in \secref{sec:ideals}) so that parity check condition (\ref{eq:pchk}) is still valid as well as BCH bound. Furthermore, from a direct analysis of the polynomial supplied by \cite{b:DVBstandard} (Normal FEC-Frame), one could observe that these specific codes (one for each selected error protection level) are \emph{primitive} and, indeed, \emph{narrow-sense}. The reasons are following

\begin{itemize}
\item \(g_1(x)\) is one of the possible primitive polynomial which has its roots in \(GF(2^{16})\). This can be quickly proved verifying that \(\alpha^{2^{16}-1}=1\) by computer aid or, more lazily, by direct consultation of any table of primitive polynomials. For the tables of primitive polynomials, the interested reader could refer to \cite{b:wicker}
\item Hence, this BCH is a narrow-sense code. In fact, by design, it follows that \(b\) must be equal to 1.
\end{itemize}

Recalling that DVB-S2 transmission section operates in Adaptive Coding Modulation (ACM) we have -- always in Normal FEC-Frame mode -- different code rates to deal with variable link conditions. Outer FEC (i.e. BCH), although there are 12 distinct operating modes, deal with only three different error protection level: \(t=12 \virgola t=10 \virgola t=8\). On the one hand we have, since this BCH is primitive, that the codeword length must be \(2^{16}-1\). On the other hand we have in Table \ref{tb:codpar} multiple codeword lengths for each operating mode and all of them do not correspond to the primitive length BCH should have. These questions raise an important point, especially in light of the above consideration as to the provided operating modes. In general, for each code rate, one could expect a different table of polynomials to multiply, whereas there is only a table of polynomials provided by \cite{b:DVBstandard}.

Then we have to conclude that DVB-S2 BCH code is \emph{shortened}. A systematic \((n\virgola k)\) code can be shortened by setting a number of the information bits to zero (i.e, zero padding). That is, a linear \((n\virgola k)\) code consisting of $k$ information bits and \(n-k\) check bits (or redundancy bits) can be shortened into a \( (n-l \virgola k-l) \) linear code by setting the most (or the least, depending on the reference direction) significant first \(l\) bits to zero. As also described in \cite{b:moon}, shortening of a code does not have bad effects on its minimum distance properties and its decoding algorithms. However, shortened cyclic code might loose its cyclic property.



\begin{table} \centering
\begin{tabular}{|c|l|}
  \hline
  % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
  \(g_1(x)\) & $1+x^2+x^3+x^5+x^{16}$ \\
  \(g_2(x)\) & $1+x+x^4+x^5+x^6+x^8+x^{16}$ \\
  \(g_3(x)\) & $1+x^2+x^3+x^4+x^5+x^7+x^8+x^9+ x^{10}+x^{11}+x^{16}$ \\
  \(g_4(x)\) & $1+x^2+x^4+x^6+x^9+x^{11}+ x^{12}+x^{14}+x^{16}$\\
  \(g_5(x)\) & $1+x+x^2+x^3+x^5+x^{8}+ x^{9}+x^{10}+x^{11}+x^{12}+x^{16}$ \\
  \(g_6(x)\) & $1+x^2+x^4+x^5+x^7+x^{8}+ x^{9}+x^{10}+x^{12}+x^{13}+x^{14}+x^{15}+x^{16}$\\
  \(g_7(x)\) & $1+x^2+x^5+x^6+x^8+x^{9}+ x^{10}+x^{11}+x^{13}+x^{15}+x^{16}$ \\
  \(g_8(x)\) & $1+x+x^2+x^5+x^6+x^{8}+ x^{9}+x^{12}+x^{13}+x^{14}+x^{16}$ \\
  \(g_9(x)\) & $1+x^5+x^{7}+ x^{9}+x^{10}+x^{11}+x^{16}$ \\
  \(g_{10}(x)\) & $1+x+x^2+x^5+x^7+x^{8}+ x^{10}+x^{12}+x^{13}+x^{14}+x^{16}$ \\
  \(g_{11}(x)\) & $1+x+x^2+x^3+x^5+x^{9}+ x^{11}+x^{12}+x^{13}+x^{16}$ \\
  \(g_{12}(x)\) & $1+x+x^5+x^6+x^{7}+ x^{9}+x^{11}+x^{12}+x^{16}$ \\
  \hline
\end{tabular}
\caption{BCH minimal polynomials for normal FECFRAME \(n\ped{LDPC}=64800\)}
\label{tb:BCHpoly}
\end{table}

\begin{table} \centering
\begin{tabular}{|c|c|c|c|c|}
  \hline
  LDPC Code  & BCH Uncoded & BCH Coded  & BCHFEC & BCH t-error\\
  Rate & Block & Block & & Correction\\
  \hline
  % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
  1/4 & 16008 & 16200 & 192 & 12 \\
  1/3 & 21408 & 21600 & 192 & 12 \\
  2/5 & 25728 & 25920 & 192 & 12 \\
  1/2 & 32208 & 32400 & 192 & 12 \\
  3/5 & 38688 & 38880 & 192 & 12 \\
  2/3 & 43040 & 43200 & 160 & 10 \\
  3/4 & 48408 & 48600 & 192 & 12 \\
  4/5 & 51648 & 51840 & 192 & 12 \\
  5/6 & 53840 & 54000 & 160 & 10 \\
  8/9 & 57472 & 57600 & 128 & 8 \\
  9/10 & 58192 & 58320 & 128 & 8 \\
  \hline
\end{tabular}
\caption{Coding parameters for normal FECFRAME \(n\ped{LDPC}=64800\)} \label{tb:codpar}
\end{table}

\subsection{LDPC}

%\section{Inner FEC: Low Density Parity Check Code}

LDPC codes \cite{b:LDPCGall} were invented in 1960 by R. Gallager. They were largely ignored until the discovery of turbo codes \cite{b:Turbo} in 1993. Since then, LDPC codes have experienced a renaissance and are now one of the most intensely studied areas in coding.
%In this article we review the basic structure of LDPC codes and the iterative algorithms that are used to decode them. We also briefly consider the state of the art of LDPC design.

%In the year 1993, C. Berrou, A. Glavieux, and P. Thitimajshima presented their
%approach to error correcting coding, termed turbo coding, to the world. The new technique, with complexity only a small factor larger than that of standard coding schemes like convolutional codes, enables performance approaching the Shannon capacity of the additive white Gaussian noise channel within a fraction of a dB.
%
%In 1960 R. Gallager completed his Ph.D. thesis, Low-Density Parity-Check Codes.
%In this remarkable thesis Gallager introduced at least two lasting concepts: a powerful bounding technique to assess the maximum-likelihood performance of coding systems, and low-density parity-check (LDPC) codes together with their associated iterative decoding algorithm.


Much of the effort in coding over the last 50 years has focused on the construction of highly structured codes with large minimum distance. The structure keeps the decoding complexity manageable, while large minimum distance is supposed to guarantee good performance. This approach, however, is not without its drawbacks.
First, it seems that finding structured codes with large minimum distance turn out to be a harder problem than researchers imagined. Finding good codes in general is, in a sense, trivial: randomly chosen codes are good with high probability. More generally, one can easily construct good codes provided one admits sufficient \emph{description complexity} into the definition of the code. This conflicts, however, with the goal of finding
highly structured codes that have simple decodings.
Second, close to capacity, minimum distance is only a poor surrogate for the performance measure of real interest. Iterative coding systems take an entirely different approach. The basic idea is the following. Codes are constructed so that the relationship between their bits (the structure of their redundancy) is \emph{locally} simple, admitting simple
\emph{local decoding}.
The local descriptions of the codes are interconnected in a complex (e.g., random-
like) manner, introducing long-range relationships between the bits. Relatively high global description complexity is thereby introduced in the interconnection between the simple local structures. Iterative decoding proceeds by performing the simple local decodings and then exchanging the results, passing messages between locales across the `complex' interconnection. The locales repeat their simple decodings, taking into account the new information provided to them from other locales. Usually, one uses a graph to
represent this process. \emph{Locales} are nodes in the graph, and interconnections are represented as edges. Thus, description complexity is introduced without adding computational complexity per se, but rather as wiring or routing complexity.

In addition to the classical representation of block codes (i.e. by \(\vet H\) matrix), another useful and common way of representing an LDPC codes is through a graphical representation called a \emph{Tanner graph} \cite{b:LDPCGall, b:moon, b:MacKay}.
Tanner graphs of LDPC codes are bipartite graphs with variable nodes on one side and constraint nodes on the other. Each variable node corresponds to a bit, and each constraint node corresponds to one parity-check constraint on the bits defining a codeword. A parity-check constraint applies to a certain subset of the codeword bits, those that participate in the constraint. The parity-check is satisfied if the XOR of the participating bits is 0 or, equivalently, the modulo 2 sum of the participating bits is 0. Edges in the graph attach variable nodes to constraint nodes indicating that the bit associated with the variable node participates in the parity-check constraint associated with the constraint node. A bit sequence associated with the variable nodes is a codeword if and only if all of the parity-checks are satisfied.

\begin{figure}\centering
\includegraphics[scale=0.8]{sparseH}
\caption{A low-density parity-check matrix with \(N = 20000\) columns of weight \(j = 3\) and \(M = 10000\) rows of weight \(k = 6\) (reference \cite{b:MacKay}).} \label{fig:sparseH}
\end{figure}

The Tanner graph representation of the LDPC code closely mirrors the more standard
parity-check matrix representation of a code. In this latter description the code is represented as the set of all binary solutions \( \vet x = (x_1 \virgola x_2 \virgola \ldots \virgola x_n)\) to a simple linear algebraic equation (parity check equations \cite{b:mcwilliams, b:wicker, b:moon, b:MacKay}) \( \vet H \vet x\ap{T} = \vet 0\ap{T}\).
The elements of the parity-check matrix are 0s and 1s, and all arithmetic is modulo 2, that is, multiplication of \(\vet x\) by a row of \(\vet H\) means taking the XOR of the bits in \(\vet x\) corresponding to the 1s in the row of \(\vet H\). The connection between the parity-check matrix representation and the Tanner graph is straightforward, and is illustrated in \figref{fig:Tanner} by means of an example.
The elements of \(\vet x\) are in one-to-one correspondence with the variable
nodes in the Tanner graph. Thus, the variable nodes correspond to the columns of \(\vet H\).
The parity checks on \(\vet x\) are in one-to-one correspondence with the constraint nodes in the Tanner graph. Thus, the constraint nodes corresponds to the rows of \(\vet H\). The edges in the Tanner graph correspond to the 1s in \(\vet H\), that is, the entry in the
\(i\)-th row and \(j\)-th column of \(\vet H\) is a 1 if and only if the \(i\)-th constraint node is connected to the \(j\)-th variable node in the Tanner graph.

The Tanner graph captures the dependency structure of the various bits.
The iterative decoding algorithms we will discuss work directly on this bipartite graph.
Iterative algorithms for LDPC codes are message-passing and flipping algorithms, both introduced by Gallager \cite{b:LDPCGall}.

\begin{figure}\centering
\includegraphics[scale=0.8]{LDPC}
\caption{A parity check matrix \(\vet H\) and the corresponding Tanner graph. To illustrate the relationship more clearly, some edge are shown in red or blue.} \label{fig:Tanner}
\end{figure}

\subsubsection{Iterative Decodings and Message-Passing}
In \emph{message-passing} decoders, messages are exchanged along the edges of the graph, and computations are performed at the nodes, as shown in \figref{fig:Belief}. Each message represents an estimate of the bit associated with the edge carrying the message.
These decoders can be understood by focusing on one bit as follows. Suppose the bits of an LDPC codeword are transmitted over a communications channel and, during transmission, some of them are corrupted so that a 1 becomes a 0 or vice versa.
Each bit node in the decoder gets to see the bit that arrived at the receiver corresponding to the one that was transmitted from the equivalent node at the
transmitter. Imagine that the node would like to know if that bit is in error or not and therefore asks all of its neighboring check nodes what they think the bit’s value should be. Each neighboring check node then asks their other neighbors what their bit values are and sends back to the original bit node the modulo 2 sum of those values.
The bit node now has several opinions as to the bit’s correct value and must somehow reconcile these opinions; it could, for example, take a majority vote. The above procedure constitutes one round or iteration of message passing.

\begin{figure}\centering
\includegraphics[scale=0.8]{beliefprop}
\caption{The principle of a message-passing decoder. Messages represent an
estimate of the bit associated with the edge carrying the message. Nodes query
neighboring nodes to collect opinions, process this information, and forward
their current estimate to their neighbors.} \label{fig:Belief}
\end{figure}

In order to improve performance, a further
such round can be performed. In more detail,
assume that those bit nodes that send their
observed bits to the checks to be summed first
ask their check node neighbors what they think is
their correct bit value. Those check nodes could
then query their other variable node neighbors
and forwarded their modulo 2 sum as an opinion.
With more information now available, the bit
nodes would have a better chance of communicating
the correct value to the check nodes, and
the opinions returned to the original node would
therefore have a better chance of being correct.
This gathering of opinions could obviously be
extended through multiple iterations; typically,
many iteration rounds are performed.

In actual decoding all nodes decode concurrently.
Each node gathers opinions from all its
neighbors and forwards to each neighbor an
opinion formed by combining the opinions of
the other neighbors. This is the source of the
term message passing. The process continues
until either a set of bits is found that satisfies all
checks or time runs out. The message passing
may proceed asynchronously. Note that with
LDPC codes, convergence to a codeword is easy
to detect since one need only verify that the parity
checks are satisfied.

The processing required for message-passing decoding LDPC codes is highly parallelizable and flexible. Each message-passing operation performed at a node depends on other nodes only through the messages that arrive at that node.
Moreover, message updating need not be synchronized. Consequently, there is great freedom to distribute in time and space the computation required to decode LDPC codes. Turbo codes are also decoded using belief propagation, but their structure does not admit the same level of atomization.

%In the above example, opinions about a bit
%were expressed as a binary value for that bit.
%Much better decoding is possible if the opinions
%are expressed as probabilities. If the transmitted
%bits are received in error with probability p, the
%probability that the observed bit is correct is 1 – p.
%If a check node forms a modulo 2 sum of k of
%these bits, the probability that the sum is correct is
%(1+(1 – 2p)k)/2. Thus, the opinions returned from
%the check nodes have a different probability of
%being correct than those coming from the channel.
%If the bit nodes properly take these probabilities
%into account when combining the opinions, better
%performance results. In the belief propagation algorithm
%the nodes assume that all incoming probabilities
%are independent and then combine them
%by applying the rules of probability.

There is a second distinct class of decoding algorithms
that is often of interest for very high speed
applications, such as optical networking.
This class of algorithms is known as flipping
algorithms. Bit flipping usually operates on
hard decisions: the information exchanged
between neighboring nodes in each iteration is a
single bit.
The basic idea of flipping is that each
bit, corresponding to a variable node assumes a
value, either 0 or 1, and, at certain times, decides
whether to flip itself (i.e., change its value from
a 1 to a 0 or vice versa). That decision depends
on the state of the neighboring check nodes
under the current values. If enough of the neighboring
checks are unsatisfied, the bit is flipped.
The notion of `enough' may be time-varying,
and it may also depend on soft information
available about the bit. Thus, under flipping,
variable nodes inform their neighboring check
nodes of their current value, and the check
nodes then return to their neighbors the parity
of their values. The underlying assumption is
that bits that are wrong will tend to have more
unsatisfied neighbors than bits that are correct.


%LDPC codes are linear binary block codes. The codewords can be expressed as the set of all binary solutions \((x_1 \virgola x_2 \virgola \ldots \virgola x_n)\) to the parity check equation
%\(\vet H \vet x\ap{T}= 0\), where the parity check matrix \(\vet H\) is a binary matrix. The codeword length is represented by \(n\). Each row of H induces one parity check
%constraint on x. The number of independent constraints is n-k, and k is the
%number of information bits that can be encoded with this code.
%Low-Density Parity-Check (LDPC) codes are called low-density because they
%are defined by giving a parity-check matrix H that is sparse, i.e., it has few
%nonzero entries.
%
%Another useful and common way of representing an LDPC codes is through a
%graphical representation called a Tanner graph, see Fig. 1. A Tanner graph of
%an LDPC code is a bipartite graph with variable nodes on one side and
%constraint or check nodes on the other side. Variable nodes correspond one-to-
%one with bits xi, hence they correspond to the columns of H. Constraint
%nodes correspond one-to-one with the parity checks that the bits xi must
%satisfy, hence they correspond to the rows of H. Edges in the graph connect
%constraint nodes to variable nodes, where an edge indicates the associated bit
%participates in the associated parity check. Thus, the edges in the graph
%correspond to the 1’s in the parity-check matrix H. A bit sequence associated
%to the variable nodes is a codeword if and only if the modulo 2 sum of the bits
%that neighbor a check node is 0 for all check nodes.



%Turbo codes have very close to Shannon limit performance at low/medium  SNR. On the contrary, turbo codes performance may be significantly worse at high SNR. In fact, their free distance (the minimum Hamming distance between different codewords, i.e., the minimum Hamming weight of a nonzero codeword) can be low. This causes BER curve to flatten following the error floor tied to \(d\ped{free}\), after the waterfall region at low SNR (typically at error rates major than \(10^{-6}\)).
%More specifically, performance of any binary code at high SNR can be well approximated by the expression of union bound, truncated to the contribution of free distance (terms at higher distance are negligible at high SNR). A small penalty deriving from sub-optimality (iterative decoding only approximates a ML decision) of iterative decoding should be taken into the account. As a consequence, we have
%\begin{equation}
%BER \simeq \frac{1}{2}\frac{w\ped{free}}{k} \mathrm{erfc} \left( \sqrt{d\ped{free} \frac{k}{n}\frac{E\ped b}{N\ped 0} }\right)
%\end{equation}

\subsubsection{Encoding Procedure for The DVB-S2 Code}

The LDPC code of DVB-S2 standard has the following structure (see the Annex A in \cite{b:DVBstandardTR})

\begin{equation}
\vet H = \left[
\begin{array}{c|c}
\vet H\ap{d} & \vet H\ap{p}
\end{array} \right]
\end{equation}
where \(\vet H\ap{d}\) is an \(r \times k\) matrix, and \(\vet H\ap{p}\) is a dual diagonal \(r \times r\) matrix that is shown below for example (\(r=5\))

\begin{equation}
\vet H\ap{p} = \left(
\begin{array}{ccccc}
1 & 0 & 0 & 0 & 0\\
1 & 1 & 0 & 0 & 0\\
0 & 1 & 1 & 0 & 0\\
0 & 0 & 1 & 1 & 0\\
0 & 0 & 0 & 1 & 1
\end{array} \right)
\end{equation}
The notation in use is the same employed as far in standard description, that is, \(r= n-k\) represents the number of redundancy bits, \(n\) the codeword length, and \(k\) the length of messages to be encoded. By now, it does not matter which rate LDPC has: clearly \(H\)'s size change with coding rates and so its composition.

Codewords, represented by vector \(\vet x\), can be divided in a systematic part, namely \(\vet  s\), and a part relevant to the redundancy (parity) bits, namely \(\vet p\), in a way such that vector \(\vet x\) can be expressed as \(\vet x=(\vet s\virgola \vet p)\ap{T}\). The encoding is accomplished by searching the parity vector \(\vet p\) which satisfies the (system) equation \(\vet {Hx}= \vet 0\). This system, as the \(\vet x\), can be divided in two contributes as follows
\begin{equation}
\vet H\ap{d} \vet s + \vet H\ap{p} \vet p= \vet 0 \text{     or     } \vet H\ap{d} \vet s =\vet H\ap{p} \vet p= \vet v
\end{equation}
which is obviously equivalent to that given before.

So the encoding process can be carried out through two steps:
\begin{enumerate}
\item Determine the auxiliary vector \(\vet v=\vet{H}\ap{d}\vet s\). The number of XOR operations to do is \((n-k)\cdot(d\ped{c}-1)\), where \(d\ped{c}\) is the number of 1s in a row of \(\vet H\ap{d}\), which is constant in a regular LDPC.
\item Determine the \(r\) parity bits by a back substitution, using the equation \(\vet H\ap{p}\vet p = \vet v\), i.e.,
\begin{equation}
\begin{align}
p_1 &= v_1 \\
p_l &= v_l + p_{l-1}  & \text{for } l= 1 \virgola 2 \virgola \ldots\virgola r
\end{align}
\end{equation}
Here the number of operations (XOR) required is \(r-1\). This is actually a matrix inversion process, which can be almost costless executed because the matrix is bi-diagonal.
\end{enumerate}
The encoder structure is shown in \figref{fig:LDPCENC}. The overall number of operations to be performed is \(n(1-R)(d\ped{c}-1)\) (\(R\), as usually indicated in the vast majority of literature, is the code rate) and thus the encoder complexity grows linearly with \(n\).

\begin{figure}\centering
\includegraphics[scale=0.8]{LDPCENC}
\caption{Encoding process of random-like LDPC codes} \label{fig:LDPCENC}
\end{figure}

The very regular structure of \(\vet H\) matrix allows to minimize the amount of memory to be allocated so as to succeed in storing the position of one in there even when using the brute force to do that. However, the full matrix, during the encoding, is recovered from compressed information, which is contained in dedicated tables for each, of course, coding rate provided.

For example, only the location of the ones in the first column of \(\vet H\ap{d}\) is described by the table (in the first table row) in the standard: the following 359 columns are obtained through a cyclic shift of the first column of a number of locations starting from the first column.
In the same way, only the location of the ones in the 361st column of H is described by the table (second table row) in the standard: the following 359 columns are obtained via a cyclic shift of a number of locations starting from the 361st column. This procedure is followed up to the last (\(k\)-th) column of \(\vet H\ap{d}\).

Let us now recall the procedure indicated by ETSI in \cite{b:DVBstandard}.
The DVB-S2 LDPC encoder systematically encodes an information block of size \(k\ped{ldpc}\), \(\vet i= (i_0\virgola i_1\virgola i_2\virgola \ldots \virgola i_{k\ped{ldpc}})\) onto a codeword of size \(n\ped{ldpc}\), \(\vet c=(i_0\virgola i_1 \virgola \ldots \virgola p_0\virgola p_1 \virgola \ldots \virgola p_{n\ped{ldpc}-k\ped{ldpc}-1})\). The transmission of codewords starts in the given order from \(i_0\) and ends with \(p_{n\ped{ldpc}-k\ped{ldpc}-1}\). LDPC code parameters \((n\ped{ldpc}\virgola k\ped{ldpc})\) are given in table    These last two parameters depend on the coding rate and the code block size, which may be either normal or short.

The procedure to calculate the parity bits for each kind of block is the following
\begin{itemize}
\item Set all the parity bits to zero, that is, \(p_0=p_1=\ldots=p_{n\ped{ldpc}-k\ped{ldpc}-1}=0\)
\item Accumulate the first information bit, namely \(i_0\), at the parity address specified in the fist row of Tables B1 through B8 in Annex B \cite{b:DVBstandard}. %For example, for a 2/3 rate, we obtain
\item The structure of \(\vet H\) matrix can be now exploited in this way: the second column, indicating over which element of the output the second information bit is accumulated, can be obtained by the first column, and so on for the other columns. Hence
    \begin{itemize}
    \item For the next 359 information bits accumulate \(i_m\) at parity bit addresses \( \left\{ x + (m \mod 360\times q)\right\} \mod (n\ped{ldpc}-k\ped{ldpc}) \) where \(x\) denotes the address of the parity bit accumulator corresponding to the first bit \(i_0\), and \(q\) is a code rate dependent constant specified in Table 7a in \cite{b:DVBstandard}.
    \item For the 361th information bit \(i\ped{360}\), the addresses of parity bit accumulators are given in the second row of the tables B1 through B8 in Annex B \cite{b:DVBstandard}. In a similar way the addresses of the parity bit accumulators for the following 359 information bits, namely \(i_m \virgola i=361\virgola 362 \virgola \ldots \virgola 719\), are obtained using the formula \( \left\{ x + (m \mod 360\times q)\right\} \mod (n\ped{ldpc}-k\ped{ldpc}) \) where \(x\) denotes the address of the parity bit accumulator corresponding to the information bit \(i_{360}\), i.e., the entries in the second row of the tables B1 through B8 in Annex B \cite{b:DVBstandard}.
    \end{itemize}
\item In a similar manner, for every group of 360 new information bits, a new row from tables B1 through B8 in Annex B \cite{b:DVBstandard} are used to find the addresses of the parity bit accumulators.

\end{itemize}

After all of the information bits are exhausted, the final parity bits are obtained as follows (this is back substitution introduced before, now executed in-place, i.e., with no use of auxiliary vector):
\begin{itemize}
\item Sequentially perform the following operations starting with \(i=1\)
\begin{equation}
p_i = p_i + p_{i-1}\virgola \text{          } i= 0 \virgola 1 \virgola \ldots\virgola n\ped{ldpc}-k\ped{ldpc}-1
\end{equation}
\item Final content of \(p_i \virgola i= 0 \virgola 1 \virgola \ldots\virgola n\ped{ldpc}-k\ped{ldpc}-1\) is equal to the parity bit \(p_i\).
\end{itemize}

Following considerations can be done:
\begin{enumerate}
\item 	The sparse matrix \(\vet H\ap d\) is constituted by Ns sub-matrices (number of rows of tables B1 through B8) with \(m\)-rows and 360-columns, each of which is specified by a row of the tables B1 through B8; in detail, addresses of ones in the first column of each matrices is specified by a row of these tables.
\item 	Each column of  the sub-matrices constituting \(\vet H\ap d\) can be obtained via a cyclic shift of the first column,  in which the shift is of a number of positions (rows) equal to \(q\). The shift is cyclic since it is reduced modulo \(m\), the number of the rows of each sub-matrix.
\item	\(\vet H\ap d\)  has a fixed number of ones per row (\(d\ped c\)), depending on coding rate.
\item 	Number of ones per column in each sub-matrix is not fixed; tables B1 through B8 in fact has \textbf{col1} columns in the first \textbf{row1} rows and \textbf{col2} columns for \textbf{row2} (=Ns-row1) rows; this means that first \textbf{row1} sub-matrices of \(\vet H\ap d\) have \textbf{col1} ones per column, while \textbf{row2} sub-matrices have \textbf{col2} ones per column.
\item \(\vet H\ap p\) is a \(m \times m\) bi-diagonal matrix.
\end{enumerate}



The code rate dependant constant \(q\) (introduced in paragraph before) allows a division of total number m of check equations in q congruence classes; each of them has 360 equations (\(m=360\cdot q\)). From this point of view and considering tables associated to LDPC coding procedure, a parity check equation can be identified by a couple of parameters \(R\) and \(Q\): the congruence class (\(R_x\)) and the position (\(Q_x\)) in the congruence class. These parameters are obtained from following relations:
\begin{subequations}
\begin{align}
R_x &= B_x \mod q \\
Q_x &= \frac{B_x}{q}
\end{align}
\end{subequations}
where \(B_x\) is a generic element of address tables B1 trough B8, \(0<R<q-1\) and \(0<Q<359\). These tables are used to address systematic bits to the corresponding check equation. 


\begin{center}\begin{tabular}{|c|cccccccccc|}
\hline
 Rate &  dc &  q &  Ns &  K bit &  m bit &  row 1 &  row 2 &  col 1 &  col 2 & N Bx \\
\hline
 1/4 &  2 &  135 &  45 &  16200 &  48600 &  15 &  30 &  12 &  3 & 270 \\
 1/3 &  3 &  120 &  60 &  21600 &  43200 &  20 &  40 &  12 &  3 & 360 \\
 2/5 &  4 &  108 &  72 &  25920 &  38880 &  24 &  48 &  12 &  3 & 432 \\
 1/2 &  5 &  90 &  90 &  32400 &  32400 &  36 &  54 &  8 &  3 & 450 \\
 3/5 &  9 &  72 &  108 &  38880 &  25920 &  36 &  72 &  12 &  3 & 648 \\
 2/3 &  8 &  60 &  120 &  43200 &  21600 &  12 &  108 &  13 &  3 & 480 \\
 3/4 &  12 &  45 &  135 &  48600 &  16200 &  15 &  120 &  12 &  3 & 540 \\
 4/5 &  16 &  36 &  144 &  51840 &  12960 &  18 &  126 &  11 &  3 & 576 \\
 5/6 &  20 &  30 &  150 &  54000 &  10800 &  15 &  135 &  13 &  3 & 600 \\
 8/9 &  25 &  20 &  160 &  57600 &  7200 &  20 &  140 &  4 &  3 & 500 \\
 9/10 &  28 &  18 &  162 &  58320 &  6480 &  18 &  144 &  4 &  3 & 504 \\
\hline
\end{tabular}\end{center}
\section{Modem Performance} \label{sec:Perf}

Spectral efficiency provided by DVB-S2 ranges from about \(0,5 \unit{bps {Hz}^{-1}}\), using the QPSK \(1/4\), to \(4,5 \unit{bps {Hz}^{-1}}\), using the 32APSK \(9/10\); \(E\ped{s}/N\ped 0\) goes from \(-2,4 \unit{dB}\) to \(16\unit{dB}\) (AWGN channel and an ideal demodulation have been assumed), as also illustrated in \figref{f:Perf2}. This performance has been computed by computer simulations \cite{b:DVBS2system, b:DVBstandardTR} at a Packet Error Rate (PER) equal to \(10^{-7}\), corresponding about to one erroneous Transport Stream Packet per transmission hour in a \(5 \unit{Mbit/s}\) video service
On an AWGN channel\footnote{We remind that the performance over AWGN channels represents in communications an upper bound to the performance over more realistic channels. For this reason, comparison of the performance between two systems can be accomplished without any loss of generalization over an AWGN environment. Comparisons under gaussian hypotheses are expected to be virtually the same over any non-gaussian environment/channel.}, DVB-S2 gives an increase of transmission capacity (about 20-35\%) compared to DVB-S and DVB-DNSG under the same transmission conditions.

The DVB-S2 system may be used in `single carrier per transponder' or in `multiple-carriers per transponders' (FDM). On a transponder with the single carrier configuration, the transmission rate \(R\ped{s}\) can be adapted to available bandwidth (at \(-3\unit{dB}\)) in order to obtain the maximum transmission capacity compatible with the acceptable signal degradation due to transponder bandwidth limitations. In the multiple-carrier configuration (Frequency Division Multiplexing), the symbol rate \(R_s\) must be adapted to the BS (Broadcasting Services) frequencies interval so as to optimize transmissive capacity while keeping the mutual interferences between adjacent carriers at acceptable level.

\figref{f:Perf} shows the performance achieved by the modem architecture with respect to the unconstrained (from modulation levels and block length of codes) Shannon limit. The ideal \(\frac{E\ped b}{N\ped 0}\) ratios in \tbref{tb:EtaPerf} for each operating mode has been derived from the ideal \(\frac{E\ped s}{N\ped 0}\) ratios by using the following dB-relation \begin{equation}
\frac{E\ped b}{N\ped 0} = \frac{E\ped s}{N\ped 0} - 10\log_{10}(\eta\ped{CM})
\end{equation}
where \(\eta\ped{CM}\) is the ideal joint efficiency of modulation and coding adopted to transmit symbols.

\figref{f:Perf2} shows, over the plane \(C/N\) -- spectral efficiency, the overall performance compared to either the constrained Shannon bounds or the DVB-S performance.
The gain of DVB-S2 with respect to DVB-S in terms of \(C/N\), for a given spectral efficiency, remains virtually constant, around \(2-2,5 \unit{dB}\) \cite{b:DVBstandardTR, b:DVBstandard}.


\begin{figure} \centering
\includegraphics[scale = 0.3]{performance}
\caption{Performance of DVB-S2 for each modulation format and coding rate at \(\mathrm{PER}=10^{-7}\) with respect to absolute Shannon limit}\label{f:Perf}
\end{figure}

\begin{figure} \centering
\includegraphics[scale = 0.7]{PvsShConstr}
\caption{Performance Shannon limits constrained} \label{f:Perf2}
\end{figure}

\begin{table}
\begin{center}\begin{tabular}{|c|p{1.88cm}||p{2.47cm}||p{2.78cm}||p{2.84cm}||}
\hline
 Modulation &  \multicolumn{1}{p{1.88cm}|}{\centering Coding rate (LDPC)} &  \multicolumn{1}{p{2.47cm}|}{\centering Spectral efficiency} &  \multicolumn{1}{p{2.78cm}|}{\centering Ideal \(E\ped{s}/N\ped 0\) for normal FECFRAME} &  \multicolumn{1}{p{2.84cm}|}{\centering Ideal \(E\ped b/ N\ped 0\) for normal FECFRAME} \\
\hline
 QPSK &  \multicolumn{1}{p{1.88cm}|}{\centering 1/4} &  \multicolumn{1}{p{2.47cm}|}{\centering 0,490243} &  \multicolumn{1}{p{2.78cm}|}{\centering -2,35} &  \multicolumn{1}{p{2.84cm}|}{\centering 0,75} \\
 QPSK &  \multicolumn{1}{p{1.88cm}|}{\centering 1/3} &  \multicolumn{1}{p{2.47cm}|}{\centering 0,656448} &  \multicolumn{1}{p{2.78cm}|}{\centering -1,24} &  \multicolumn{1}{p{2.84cm}|}{\centering 0,59} \\
 QPSK &  \multicolumn{1}{p{1.88cm}|}{\centering 2/5} &  \multicolumn{1}{p{2.47cm}|}{\centering 0,789412} &  \multicolumn{1}{p{2.78cm}|}{\centering -0,3} &  \multicolumn{1}{p{2.84cm}|}{\centering 0,73} \\
 QPSK &  \multicolumn{1}{p{1.88cm}|}{\centering 1/2} &  \multicolumn{1}{p{2.47cm}|}{\centering 0,988858} &  \multicolumn{1}{p{2.78cm}|}{\centering 1} &  \multicolumn{1}{p{2.84cm}|}{\centering 1,05} \\
 QPSK &  \multicolumn{1}{p{1.88cm}|}{\centering 3/5} &  \multicolumn{1}{p{2.47cm}|}{\centering 1,188304} &  \multicolumn{1}{p{2.78cm}|}{\centering 2,23} &  \multicolumn{1}{p{2.84cm}|}{\centering 1,48} \\
 QPSK &  \multicolumn{1}{p{1.88cm}|}{\centering 2/3} &  \multicolumn{1}{p{2.47cm}|}{\centering 1,322253} &  \multicolumn{1}{p{2.78cm}|}{\centering 3,1} &  \multicolumn{1}{p{2.84cm}|}{\centering 1,89} \\
 QPSK &  \multicolumn{1}{p{1.88cm}|}{\centering 3/4} &  \multicolumn{1}{p{2.47cm}|}{\centering 1,487473} &  \multicolumn{1}{p{2.78cm}|}{\centering 4,03} &  \multicolumn{1}{p{2.84cm}|}{\centering 2,31} \\
 QPSK &  \multicolumn{1}{p{1.88cm}|}{\centering 4/5} &  \multicolumn{1}{p{2.47cm}|}{\centering 1,587196} &  \multicolumn{1}{p{2.78cm}|}{\centering 4,68} &  \multicolumn{1}{p{2.84cm}|}{\centering 2,67} \\
 QPSK &  \multicolumn{1}{p{1.88cm}|}{\centering 5/6} &  \multicolumn{1}{p{2.47cm}|}{\centering 1,654663} &  \multicolumn{1}{p{2.78cm}|}{\centering 5,18} &  \multicolumn{1}{p{2.84cm}|}{\centering 2,99} \\
 QPSK &  \multicolumn{1}{p{1.88cm}|}{\centering 8/9} &  \multicolumn{1}{p{2.47cm}|}{\centering 1,766451} &  \multicolumn{1}{p{2.78cm}|}{\centering 6,2} &  \multicolumn{1}{p{2.84cm}|}{\centering 3,73} \\
 QPSK &  \multicolumn{1}{p{1.88cm}|}{\centering 9/10} &  \multicolumn{1}{p{2.47cm}|}{\centering 1,788612} &  \multicolumn{1}{p{2.78cm}|}{\centering 6,42} &  \multicolumn{1}{p{2.84cm}|}{\centering 3,89} \\
 8PSK &  \multicolumn{1}{p{1.88cm}|}{\centering 3/5} &  \multicolumn{1}{p{2.47cm}|}{\centering 1,779991} &  \multicolumn{1}{p{2.78cm}|}{\centering 5,5} &  \multicolumn{1}{p{2.84cm}|}{\centering 3,00} \\
 8PSK &  \multicolumn{1}{p{1.88cm}|}{\centering 2/3} &  \multicolumn{1}{p{2.47cm}|}{\centering 1,980636} &  \multicolumn{1}{p{2.78cm}|}{\centering 6,62} &  \multicolumn{1}{p{2.84cm}|}{\centering 3,65} \\
 8PSK &  \multicolumn{1}{p{1.88cm}|}{\centering 3/4} &  \multicolumn{1}{p{2.47cm}|}{\centering 2,228124} &  \multicolumn{1}{p{2.78cm}|}{\centering 7,91} &  \multicolumn{1}{p{2.84cm}|}{\centering 4,43} \\
 8PSK &  \multicolumn{1}{p{1.88cm}|}{\centering 5/6} &  \multicolumn{1}{p{2.47cm}|}{\centering 2,478562} &  \multicolumn{1}{p{2.78cm}|}{\centering 9,35} &  \multicolumn{1}{p{2.84cm}|}{\centering 5,41} \\
 8PSK &  \multicolumn{1}{p{1.88cm}|}{\centering 8/9} &  \multicolumn{1}{p{2.47cm}|}{\centering 2,646012} &  \multicolumn{1}{p{2.78cm}|}{\centering 10,69} &  \multicolumn{1}{p{2.84cm}|}{\centering 6,46} \\
 8PSK &  \multicolumn{1}{p{1.88cm}|}{\centering 9/10} &  \multicolumn{1}{p{2.47cm}|}{\centering 2,679207} &  \multicolumn{1}{p{2.78cm}|}{\centering 10,98} &  \multicolumn{1}{p{2.84cm}|}{\centering 6,70} \\
 16APSK &  \multicolumn{1}{p{1.88cm}|}{\centering 2/3} &  \multicolumn{1}{p{2.47cm}|}{\centering 2,637201} &  \multicolumn{1}{p{2.78cm}|}{\centering 8,97} &  \multicolumn{1}{p{2.84cm}|}{\centering 4,76} \\
 16APSK &  \multicolumn{1}{p{1.88cm}|}{\centering 3/4} &  \multicolumn{1}{p{2.47cm}|}{\centering 2,966728} &  \multicolumn{1}{p{2.78cm}|}{\centering 10,21} &  \multicolumn{1}{p{2.84cm}|}{\centering 5,49} \\
 16APSK &  \multicolumn{1}{p{1.88cm}|}{\centering 4/5} &  \multicolumn{1}{p{2.47cm}|}{\centering 3,165623} &  \multicolumn{1}{p{2.78cm}|}{\centering 11,03} &  \multicolumn{1}{p{2.84cm}|}{\centering 6,03} \\
 16APSK &  \multicolumn{1}{p{1.88cm}|}{\centering 5/6} &  \multicolumn{1}{p{2.47cm}|}{\centering 3,300184} &  \multicolumn{1}{p{2.78cm}|}{\centering 11,61} &  \multicolumn{1}{p{2.84cm}|}{\centering 6,42} \\
 16APSK &  \multicolumn{1}{p{1.88cm}|}{\centering 8/9} &  \multicolumn{1}{p{2.47cm}|}{\centering 3,523143} &  \multicolumn{1}{p{2.78cm}|}{\centering 12,89} &  \multicolumn{1}{p{2.84cm}|}{\centering 7,42} \\
 16APSK &  \multicolumn{1}{p{1.88cm}|}{\centering 9/10} &  \multicolumn{1}{p{2.47cm}|}{\centering 3,567342} &  \multicolumn{1}{p{2.78cm}|}{\centering 13,13} &  \multicolumn{1}{p{2.84cm}|}{\centering 7,61} \\
 32APSK &  \multicolumn{1}{p{1.88cm}|}{\centering 3/4} &  \multicolumn{1}{p{2.47cm}|}{\centering 3,703295} &  \multicolumn{1}{p{2.78cm}|}{\centering 12,73} &  \multicolumn{1}{p{2.84cm}|}{\centering 7,04} \\
 32APSK &  \multicolumn{1}{p{1.88cm}|}{\centering 4/5} &  \multicolumn{1}{p{2.47cm}|}{\centering 3,951571} &  \multicolumn{1}{p{2.78cm}|}{\centering 13,64} &  \multicolumn{1}{p{2.84cm}|}{\centering 7,67} \\
 32APSK &  \multicolumn{1}{p{1.88cm}|}{\centering 5/6} &  \multicolumn{1}{p{2.47cm}|}{\centering 4,11954} &  \multicolumn{1}{p{2.78cm}|}{\centering 14,28} &  \multicolumn{1}{p{2.84cm}|}{\centering 8,13} \\
 32APSK &  \multicolumn{1}{p{1.88cm}|}{\centering 8/9} &  \multicolumn{1}{p{2.47cm}|}{\centering 4,397854} &  \multicolumn{1}{p{2.78cm}|}{\centering 15,69} &  \multicolumn{1}{p{2.84cm}|}{\centering 9,26} \\
 32APSK &  \multicolumn{1}{p{1.88cm}|}{\centering 9/10} &  \multicolumn{1}{p{2.47cm}|}{\centering 4,453027} &  \multicolumn{1}{p{2.78cm}|}{\centering 16,05} &  \multicolumn{1}{p{2.84cm}|}{\centering 9,56} \\
\hline
\end{tabular}\end{center}
\caption{DVB-S2 performance at \(\unit{PER}=10^{-7}\)}\label{tb:EtaPerf}
\end{table} 